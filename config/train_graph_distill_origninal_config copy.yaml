graph_model:
  hidden_channels: 256
  num_layers: 2
  num_heads: 8
  dropout: 0.33
  edge_dropout: 0.48
  input_dropout: 0.35
  input_norm: false
  different_embedding: saved_embeddings/better_bert.npy
  learning_rate: 0.00152
  weight_decay: 0.00055
  trial_number: 9999999
  batch_size: 256
  test: true
  label_smoothing: 0.01
  number_of_sampled_neighbors: 463
  custom_logger_name: original_distill_bert